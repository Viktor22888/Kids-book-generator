import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
import os

class NeuralTextGenerator:
 
    def __init__(self, mode="lightweight"):
       
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.mode = mode
        self.model = None
        self.tokenizer = None
        self.pipe = None
        self.api_key = None  
        
        if mode == "lightweight":
            self._load_lightweight_model()
        elif mode == "api":
            self._setup_api()
        elif mode == "local":
            self._load_local_model()
    
    def _load_lightweight_model(self):
      

        
        try:
 
            model_name = "sberbank-ai/rugpt3small_based_on_gpt2"
            
            print("üì• –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ (—ç—Ç–æ –∑–∞–π–º–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ)...")
            print("üí° –ü–æ—Å–ª–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –ë–ï–ó –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞ –∏ –ë–ï–°–ü–õ–ê–¢–ù–û!")
            
            self.tokenizer = AutoTokenizer.from_pretrained(
                model_name,
                local_files_only=False,
                resume_download=True  
            )
            
            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token
            
            self.model = AutoModelForCausalLM.from_pretrained(
                model_name,
                torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
                local_files_only=False,
                resume_download=True
            )
            self.model.to(self.device)
            self.model.eval()
            print("‚úÖ –ë–ï–°–ü–õ–ê–¢–ù–ê–Ø –Ω–µ–π—Ä–æ—Å–µ—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ!")
            print("üéâ –¢–µ–ø–µ—Ä—å —Ä–∞–±–æ—Ç–∞–µ—Ç –û–§–õ–ê–ô–ù –∏ –ë–ï–°–ü–õ–ê–¢–ù–û!")
            return True
        except Exception as e:
            error_msg = str(e)
            if "timeout" in error_msg.lower() or "timed out" in error_msg.lower():
                print(f"‚è±Ô∏è  –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏: {error_msg[:100]}")
                print("üí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ - –º–æ–¥–µ–ª—å –±–æ–ª—å—à–∞—è (~300MB)")
                print("üí° –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ä–µ–∂–∏–º –±–µ–∑ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ (neural_mode=None)")
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {error_msg[:200]}")
                print("üí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ä–µ–∂–∏–º –±–µ–∑ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏")
            return False
    
    def _setup_api(self):
      
        print("üåê –†–µ–∂–∏–º API: –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –∏–Ω—Ç–µ—Ä–Ω–µ—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")
        print("üá∑üá∫ –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –ë–ï–°–ü–õ–ê–¢–ù–´–• —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö API:")
        print("   - YANDEX_API_KEY –¥–ª—è Yandex GPT (–±–µ—Å–ø–ª–∞—Ç–Ω—ã–π —Ç–∞—Ä–∏—Ñ)")
        print("   - GIGACHAT_API_KEY –¥–ª—è GigaChat –æ—Ç –°–±–µ—Ä–∞ (–±–µ—Å–ø–ª–∞—Ç–Ω—ã–π —Ç–∞—Ä–∏—Ñ)")
        
   
        self.yandex_api_key = os.getenv("YANDEX_API_KEY")
    
        self.gigachat_auth_key = os.getenv("GIGACHAT_AUTH_KEY") 
        self.gigachat_client_id = os.getenv("GIGACHAT_CLIENT_ID")
        self.gigachat_client_secret = os.getenv("GIGACHAT_CLIENT_SECRET")
   
        self.gigachat_api_key = os.getenv("GIGACHAT_API_KEY") or self.gigachat_auth_key
        self.yandex_folder_id = os.getenv("YANDEX_FOLDER_ID")  
        
      
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        self.api_key = self.yandex_api_key or self.gigachat_api_key or self.gigachat_auth_key or self.openai_api_key
        
        if not self.api_key:
            print("‚ö†Ô∏è  API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω!")
            print("üí° –î–ª—è –ë–ï–°–ü–õ–ê–¢–ù–û–ô —Ä–∞–±–æ—Ç—ã —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ:")
            print("   - YANDEX_API_KEY (–±–µ—Å–ø–ª–∞—Ç–Ω—ã–π —Ç–∞—Ä–∏—Ñ Yandex GPT)")
            print("   - GIGACHAT_API_KEY (–±–µ—Å–ø–ª–∞—Ç–Ω—ã–π —Ç–∞—Ä–∏—Ñ GigaChat)")
            print("üí° –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ neural_mode='lightweight' –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏")
            return False
        

        if self.yandex_api_key:
            self.api_provider = "yandex"
            print("‚úÖ –ù–∞–π–¥–µ–Ω Yandex GPT API –∫–ª—é—á (–±–µ—Å–ø–ª–∞—Ç–Ω—ã–π —Ç–∞—Ä–∏—Ñ)")
        elif self.gigachat_auth_key or (self.gigachat_client_id and self.gigachat_client_secret):
            self.api_provider = "gigachat"
            if self.gigachat_auth_key:
                print("‚úÖ –ù–∞–π–¥–µ–Ω GigaChat Authorization Key (–±–µ—Å–ø–ª–∞—Ç–Ω—ã–π —Ç–∞—Ä–∏—Ñ)")
            else:
                print("‚úÖ –ù–∞–π–¥–µ–Ω GigaChat Client ID/Secret (–±–µ—Å–ø–ª–∞—Ç–Ω—ã–π —Ç–∞—Ä–∏—Ñ)")
        elif self.gigachat_api_key:
            self.api_provider = "gigachat"
            print("‚úÖ –ù–∞–π–¥–µ–Ω GigaChat API –∫–ª—é—á (–±–µ—Å–ø–ª–∞—Ç–Ω—ã–π —Ç–∞—Ä–∏—Ñ)")
        elif self.openai_api_key:
            self.api_provider = "openai"
            print("‚ö†Ô∏è  –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è OpenAI API (–ø–ª–∞—Ç–Ω–æ)")
        else:
            self.api_provider = None
        
        return True
    
    def _load_local_model(self):

        print("üìÇ –ü–æ–∏—Å–∫ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏...")

        local_path = os.getenv("LOCAL_MODEL_PATH", None)
        
        if local_path and os.path.exists(local_path):
            try:
                self.tokenizer = AutoTokenizer.from_pretrained(local_path)
                self.model = AutoModelForCausalLM.from_pretrained(local_path)
                self.model.to(self.device)
                self.model.eval()
                print("‚úÖ –õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
                return True
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏: {e}")
        
        print("üí° –õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ lightweight —Ä–µ–∂–∏–º.")
        return False
    
    def generate_with_neural_network(self, prompt, max_length=200, temperature=0.8):
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ä–µ–∞–ª—å–Ω–æ–π –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
        """
        if self.mode == "lightweight" and self.model and self.tokenizer:
            return self._generate_local(prompt, max_length, temperature)
        elif self.mode == "api":
            return self._generate_api(prompt, max_length, temperature)
        elif self.mode == "local" and self.model and self.tokenizer:
            return self._generate_local(prompt, max_length, temperature)
        else:
            return None
    
    def _generate_local(self, prompt, max_length, temperature):
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
        """
        try:
            full_prompt = f"–î–µ—Ç—Å–∫–∞—è –∏—Å—Ç–æ—Ä–∏—è: {prompt}. –ù–∞—á–Ω–µ–º —Ä–∞—Å—Å–∫–∞–∑:"
            
           
            inputs = self.tokenizer.encode(full_prompt, return_tensors="pt").to(self.device)
            

            with torch.no_grad():
                outputs = self.model.generate(
                    inputs,
                    max_length=len(inputs[0]) + max_length,
                    num_return_sequences=1,
                    temperature=temperature,
                    do_sample=True,
                    pad_token_id=self.tokenizer.eos_token_id,
                    top_p=0.9,
                    repetition_penalty=1.2,
                    no_repeat_ngram_size=3
                )
            
           
            generated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            
           
            new_text = generated_text[len(full_prompt):].strip()
            
            return new_text
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
            return None
    
    def _generate_api(self, prompt, max_length, temperature):
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ API (—Ç—Ä–µ–±—É–µ—Ç –∏–Ω—Ç–µ—Ä–Ω–µ—Ç)
        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ë–ï–°–ü–õ–ê–¢–ù–´–ï —Ä–æ—Å—Å–∏–π—Å–∫–∏–µ API: Yandex GPT –∏ GigaChat
        """
        try:
            import requests
            
     
            if self.api_provider == "yandex" and self.yandex_api_key:
                if not self.yandex_folder_id:
                    print("‚ö†Ô∏è  YANDEX_FOLDER_ID –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ù—É–∂–µ–Ω –¥–ª—è Yandex GPT.")
                    return None
                
                url = "https://llm.api.cloud.yandex.net/foundationModels/v1/completion"
                headers = {
                    "Authorization": f"Api-Key {self.yandex_api_key}",
                    "Content-Type": "application/json"
                }
                
                data = {
                    "modelUri": f"gpt://{self.yandex_folder_id}/yandexgpt/latest",
                    "completionOptions": {
                        "stream": False,
                        "temperature": temperature,
                        "maxTokens": str(max_length)
                    },
                    "messages": [
                        {
                            "role": "system",
                            "text": "–¢—ã —Ç–∞–ª–∞–Ω—Ç–ª–∏–≤—ã–π –¥–µ—Ç—Å–∫–∏–π –ø–∏—Å–∞—Ç–µ–ª—å. –ü–∏—à–∏ –ø—Ä–æ—Å—Ç—ã–µ, –ø–æ–Ω—è—Ç–Ω—ã–µ –∏—Å—Ç–æ—Ä–∏–∏ –¥–ª—è –¥–µ—Ç–µ–π 5-10 –ª–µ—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. –ö–∞–∂–¥–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –¥–æ–ª–∂–Ω–∞ —Å–æ–¥–µ—Ä–∂–∞—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ —Å–æ–±—ã—Ç–∏–µ. –ò–∑–±–µ–≥–∞–π –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π."
                        },
                        {
                            "role": "user",
                            "text": prompt
                        }
                    ]
                }
                
                response = requests.post(url, headers=headers, json=data, timeout=30)
                
                if response.status_code == 200:
                    result = response.json()
                    return result["result"]["alternatives"][0]["message"]["text"]
                else:
                    print(f"–û—à–∏–±–∫–∞ Yandex API: {response.status_code} - {response.text}")
                    return None
            
        
            elif self.api_provider == "gigachat":
        
                auth_url = "https://ngw.devices.sberbank.ru:9443/api/v2/oauth"
                
      
                if self.gigachat_auth_key:
       
                    import uuid
                    auth_headers = {
                        "Authorization": f"Basic {self.gigachat_auth_key}",
                        "Content-Type": "application/x-www-form-urlencoded",
                        "Accept": "application/json",
                        "RqUID": str(uuid.uuid4())  
                    }
                elif self.gigachat_client_id and self.gigachat_client_secret:
           
                    import base64
                    import uuid
                    credentials = f"{self.gigachat_client_id}:{self.gigachat_client_secret}"
                    encoded_credentials = base64.b64encode(credentials.encode()).decode()
                    auth_headers = {
                        "Authorization": f"Basic {encoded_credentials}",
                        "Content-Type": "application/x-www-form-urlencoded",
                        "Accept": "application/json",
                        "RqUID": str(uuid.uuid4())
                    }
                elif self.gigachat_api_key:
          
                    auth_headers = {
                        "Authorization": f"Bearer {self.gigachat_api_key}",
                        "Content-Type": "application/x-www-form-urlencoded",
                        "Accept": "application/json"
                    }
                else:
                    print("‚ö†Ô∏è  GigaChat –∫–ª—é—á–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                    return None
                
                auth_data = {"scope": "GIGACHAT_API_PERS"}
                
                try:
                   
                    import urllib3
                    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
                    auth_response = requests.post(auth_url, headers=auth_headers, data=auth_data, timeout=10, verify=False)
                    if auth_response.status_code != 200:
                        print(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–∞ GigaChat: {auth_response.status_code}")
                        return None
                    
                    access_token = auth_response.json().get("access_token")
                    if not access_token:
                        print("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ç–æ–∫–µ–Ω GigaChat")
                        return None
                    
                    api_url = "https://gigachat.devices.sberbank.ru/api/v1/chat/completions"
                    api_headers = {
                        "Authorization": f"Bearer {access_token}",
                        "Content-Type": "application/json"
                    }
                    
                    api_data = {
                        "model": "GigaChat",
                        "messages": [
                            {
                                "role": "system", 
                                "content": "–¢—ã —Ç–∞–ª–∞–Ω—Ç–ª–∏–≤—ã–π –¥–µ—Ç—Å–∫–∏–π –ø–∏—Å–∞—Ç–µ–ª—å. –ü–∏—à–∏ –ø—Ä–æ—Å—Ç—ã–µ, –ø–æ–Ω—è—Ç–Ω—ã–µ –∏—Å—Ç–æ—Ä–∏–∏ –¥–ª—è –¥–µ—Ç–µ–π 5-10 –ª–µ—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. –ö–∞–∂–¥–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –¥–æ–ª–∂–Ω–∞ —Å–æ–¥–µ—Ä–∂–∞—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ —Å–æ–±—ã—Ç–∏–µ –∏–ª–∏ —Ä–∞–∑–≤–∏—Ç–∏–µ —Å—é–∂–µ—Ç–∞. –ò–∑–±–µ–≥–∞–π –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π. –ü–∏—à–∏ —è—Ä–∫–æ –∏ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ."
                            },
                            {"role": "user", "content": prompt}
                        ],
                        "max_tokens": max_length,
                        "temperature": temperature
                    }
                    
                    api_response = requests.post(api_url, headers=api_headers, json=api_data, timeout=30, verify=False)
                    
                    if api_response.status_code == 200:
                        result = api_response.json()
                        return result["choices"][0]["message"]["content"]
                    else:
                        print(f"–û—à–∏–±–∫–∞ GigaChat API: {api_response.status_code} - {api_response.text}")
                        return None
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ GigaChat: {e}")
                    return None
            
            elif self.api_provider == "openai" and self.openai_api_key:
                headers = {
                    "Authorization": f"Bearer {self.openai_api_key}",
                    "Content-Type": "application/json"
                }
                
                data = {
                    "model": "gpt-3.5-turbo",
                    "messages": [
                        {"role": "system", "content": "–¢—ã –¥–µ—Ç—Å–∫–∏–π –ø–∏—Å–∞—Ç–µ–ª—å. –ü–∏—à–∏ –ø—Ä–æ—Å—Ç—ã–µ, –ø–æ–Ω—è—Ç–Ω—ã–µ –∏—Å—Ç–æ—Ä–∏–∏ –¥–ª—è –¥–µ—Ç–µ–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."},
                        {"role": "user", "content": f"–ù–∞–ø–∏—à–∏ –¥–µ—Ç—Å–∫—É—é –∏—Å—Ç–æ—Ä–∏—é –æ: {prompt}"}
                    ],
                    "max_tokens": max_length,
                    "temperature": temperature
                }
                
                response = requests.post(
                    "https://api.openai.com/v1/chat/completions",
                    headers=headers,
                    json=data,
                    timeout=30
                )
                
                if response.status_code == 200:
                    result = response.json()
                    return result["choices"][0]["message"]["content"]
                else:
                    print(f"–û—à–∏–±–∫–∞ OpenAI API: {response.status_code}")
                    return None
            else:
                print("‚ö†Ô∏è  API –∫–ª—é—á –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
                return None
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ API –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
            return None


class GPT4AllGenerator:

    
    def __init__(self):
        try:
            from gpt4all import GPT4All
            print("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è GPT4All...")
            self.model = GPT4All("ggml-gpt4all-j-v1.3-groovy")
            print("‚úÖ GPT4All –≥–æ—Ç–æ–≤!")
        except ImportError:
            print("‚ùå GPT4All –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install gpt4all")
            self.model = None
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ GPT4All: {e}")
            self.model = None
    
    def generate(self, prompt, max_tokens=200):
        if not self.model:
            return None
        
        try:
            full_prompt = f"–ù–∞–ø–∏—à–∏ –¥–µ—Ç—Å–∫—É—é –∏—Å—Ç–æ—Ä–∏—é –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ –æ: {prompt}\n\n–ò—Å—Ç–æ—Ä–∏—è:"
            response = self.model.generate(full_prompt, max_tokens=max_tokens, temp=0.8)
            return response
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
            return None

